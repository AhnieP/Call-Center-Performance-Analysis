# Call-Center-Performance-Analysis
This project explores the performance of a call center using historical interaction data. It evaluates key performance indicators (KPIs) such as agent responsiveness, call resolution times, queue management, and overall customer service efficiency. The goal is to identify improvement areas to boost service delivery and agent productivity.

# ðŸ“ž Call Center Performance Analysis

This project explores the performance of a call center using historical interaction data. It evaluates key performance indicators (KPIs) such as agent responsiveness, call resolution times, queue management, and overall customer service efficiency. The goal is to identify improvement areas to boost service delivery and agent productivity.

## Overview

The dataset contains information about customer service interactions, including call types, durations, wait times, agent IDs, and resolutions. The analysis provides insight into:

- Average handling and waiting times
- Peak call periods
- Agent performance metrics
- Resolution rates
- Customer interaction patterns

## Dataset Summary

- **Fields include**:
  - `Call ID`
  - `Agent Name`
  - `Call Date & Time`
  - `Call Duration`
  - `Wait Time`
  - `Call Type` (Inbound/Outbound)
  - `Customer Satisfaction`
  - `Issue Resolved` (Yes/No)

## Objectives

- Analyze overall call volume trends
- Identify high-performing and low-performing agents
- Evaluate response and resolution efficiency
- Detect bottlenecks in call flow and queue times
- Understand customer satisfaction trends

## Key Insights from Call Center Q1 Performance Analytics

### 1. High Call Volume and Agent Workload
- The call center managed a total of 5,000 calls with 8 agents during Q1.
- On average, each agent handled approximately 625 calls, indicating a high workload and the need for optimal staffing and shift management.

### 2. Fast Average Speed of Answer
- The average speed of answer is 55 seconds.
- This reflects operational efficiency and a quick response time, contributing positively to customer experience.

### 3. High Answer Rate
- 81% of incoming calls (4,000 out of 5,000) were answered.
- However, a significant 19% (1,000 calls) were missed or unanswered, highlighting potential gaps during peak periods or under-resourcing.

### 4. Strong Resolution Rate
- 90% of answered calls were successfully resolved.
- This indicates effective issue handling and agent capability. The remaining 10% unresolved calls warrant further investigation.

### 5. Moderate Customer Satisfaction
- The average satisfaction rating is 3 out of 5.
- This suggests that while technical efficiency is high, the quality of customer interaction may need improvement, particularly in areas like communication tone and empathy.

### 6. Best Performing Agent: Dan
- Dan has the highest satisfaction rating and handled a large number of calls across various topics.
- His performance can be analyzed and used as a benchmark or training model for other agents.

### 7. Technical Support Dominates Call Topics
- Technical Support received the highest number of calls (1,564 out of 3,646 total categorized calls).
- This highlights a need for better technical support resources, self-service options, or product quality improvement.

### 8. Declining Satisfaction Over Time
- Satisfaction ratings dropped significantly from January to February and slightly improved in March.
- This trend may be due to staffing issues, operational strain, or service issues and should be analyzed further.

### 9. Talk Duration Highest for Jim
- Jim logged the longest cumulative talk time (151K seconds), above the average of other agents.
- This could indicate that Jim handles more complex queries or potential inefficiencies in call handling.

### 10. Underperforming Agents: Diane and Joe
- Diane and Joe recorded the lowest satisfaction ratings and relatively low task volumes.
- These agents may benefit from additional training or performance support to improve output and customer satisfaction.


## Tools Used

- **Excel** â€“ Data cleaning & exploration  
- **Power BI** â€“ Visual dashboard development  

### Recommendations

1. **Conduct Performance Review and Coaching**
   - Analyze low-performing agents' call recordings and provide targeted coaching on communication skills, customer engagement, and problem-solving.

2. **Use High-Performing Agents as Role Models**
   - Leverage the approach of top agents like Dan to develop training materials and best practices for the team.

3. **Implement or Expand Self-Service Channels**
   - Given the high volume of technical support inquiries, create or update self-help guides, FAQs, and chatbots to deflect basic inquiries and reduce agent load.

4. **Optimize Staffing During Peak Hours**
   - Use historical call data to identify peak periods and ensure sufficient agent coverage, especially around mid-day when call volume is highest.

5. **Monitor and Improve Customer Experience**
   - Introduce post-call surveys, sentiment analysis, or QA audits focused on customer-agent interaction quality to improve satisfaction beyond just resolution.

6. **Address Root Causes Behind February Satisfaction Drop**
   - Investigate internal or external events during February (e.g., system outages, staff turnover, high ticket volumes) to prevent similar dips in the future.

7. **Establish KPIs and Regular Reporting**
   - Monitor agent talk time, satisfaction, and resolution KPIs monthly to detect trends early and intervene proactively.

8. **Re-evaluate Unanswered Call Rate**
   - Explore callback technology or automated queue updates to reduce customer drop-offs from unanswered calls.


## Conclusion

The Q1 performance analysis indicates that the call center is operationally strong, with a high resolution rate and fast response times. However, agent productivity varies significantly, with a few top performers and others lagging in satisfaction and call handling. Customer satisfaction remains moderate and has declined over time, suggesting a gap between service speed and experience quality. The dominance of technical support calls highlights recurring customer issues, while the volume of unanswered calls and a notable satisfaction drop in February point to staffing or workflow inefficiencies during peak periods.

